{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290a5dcf",
   "metadata": {},
   "source": [
    "# Flow on 2d toy data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71a959",
   "metadata": {},
   "source": [
    "1. Data generation\n",
    "2. Model training\n",
    "3. Visual inspection of model generation vs actual\n",
    "4. Building a classifier to distinguish original from generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b0f53",
   "metadata": {},
   "source": [
    "https://github.com/acids-ircam/pytorch_flows/blob/master/flows_01.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from gen import utils, data, ae, vae, flow\n",
    "\n",
    "from torch import distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0662454",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 2\n",
    "n_flows = 3\n",
    "n_z = 2\n",
    "n_h = 200\n",
    "p = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = flow.NNDiagGaussian(\n",
    "    mean_encoder_model=ae.get_encoder_model(n_in, n_h, p, n_z),\n",
    "    logvar_encoder_model=ae.get_encoder_model(n_in, n_h, p, n_z)\n",
    ")\n",
    "# encoder = nf.distributions.NNDiagGaussian(encoder_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110df928",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.as_tensor(np.zeros((3, n_in)), dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ae05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z, log_q = encoder(x)\n",
    "print(f'{z=}, \\n{log_q=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b97ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.log_prob(z, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced8b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z, log_det = flow.Planar((n_z,))(z)\n",
    "print(f'{z=}, \\n{log_det=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc03e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = distributions.MultivariateNormal(torch.zeros(n_z),\n",
    "                                         torch.eye(n_z)) # prior in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35682e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = [flow.Planar((n_z,)) for k in range(n_flows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b51215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder = flow.NNDiagGaussianDecoder(\n",
    "#     ae.get_decoder_model(n_in, n_h, p, n_z)\n",
    "# )abs\n",
    "decoder = flow.NNDiagGaussian(\n",
    "    ae.get_decoder_model(n_in, n_h, p, n_z),\n",
    "    ae.get_decoder_model(n_in, n_h, p, n_z),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.log_prob(x,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5221a406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r, _ = decoder(z)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4200\n",
    "y_col = 'target'\n",
    "pattern = 'checkerboard'\n",
    "all_train_data = data.DataGenerator.generate(pattern, n).assign(**{y_col: np.random.choice([0,1], size=n)})\n",
    "all_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(all_train_data['x_0'], all_train_data['x_1'], alpha=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8355f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter(valid_pct=.2)(all_train_data)\n",
    "\n",
    "original_features = L([c for c in all_train_data.columns if c != 'id' and c != y_col])\n",
    "\n",
    "to = TabularPandas(all_train_data, procs=[FillMissing, Normalize],\n",
    "                   cont_names=original_features,\n",
    "                   y_names=y_col,\n",
    "                   splits=splits)\n",
    "\n",
    "bs = 32\n",
    "kld_weight = .05\n",
    "dls = to.dataloaders(bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec8409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_in = 2\n",
    "n_flows = 3\n",
    "n_z = 2\n",
    "n_h = 200\n",
    "p = .01\n",
    "\n",
    "prior = distributions.MultivariateNormal(torch.zeros(n_z),\n",
    "                                         torch.eye(n_z)) # prior in latent space\n",
    "\n",
    "encoder = flow.NNDiagGaussian(\n",
    "    mean_encoder_model=ae.get_encoder_model(n_in, n_h, p, n_z),\n",
    "    logvar_encoder_model=ae.get_encoder_model(n_in, n_h, p, n_z)\n",
    ")\n",
    "\n",
    "flows = [flow.Planar((n_z,)) for k in range(n_flows)]\n",
    "\n",
    "decoder = flow.NNDiagGaussian(\n",
    "    ae.get_decoder_model(n_in, n_h, p, n_z),\n",
    "    ae.get_decoder_model(n_in, n_h, p, n_z),\n",
    ")\n",
    "\n",
    "model = flow.NormalizingFlow(prior, encoder, flows, decoder)\n",
    "\n",
    "loss_func = flow.Flow_Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "learn = Learner(dls, model, loss_func=loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef2d404",
   "metadata": {},
   "source": [
    "var = std^2\n",
    "log(std) = log(sqrt(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = learn.lr_find()\n",
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c48abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, lr_max=lrs.valley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(rec, ori, mu, var), _ = learn.get_preds(ds_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, report = utils.check_identifiability_of_generated_data(ori, rec, original_features)\n",
    "fig.show()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c772f1",
   "metadata": {},
   "source": [
    "## Clicking through data patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07c944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patterns = ['twospirals', 'twomoons', 'sign', 'abs', 'sinewave', 'crescentcube', 'crescent', 'gaussian', 'checkerboard']\n",
    "\n",
    "pattern = widgets.Dropdown(description='pattern', options=patterns, value='checkerboard')\n",
    "n_data = widgets.IntText(description='data points', value=4_200)\n",
    "n_epoch = widgets.IntText(description='epochs', value=7)\n",
    "n_flows = widgets.IntText(description='n_flows', value=3)\n",
    "bs = widgets.IntText(description='bs', value=256)\n",
    "ui = widgets.VBox([pattern, n_data, n_epoch, n_flows, bs])\n",
    "\n",
    "def run_stuff(p, n, epochs, n_flows, bs):\n",
    "    # generating data\n",
    "    y_col = 'target'\n",
    "    all_train_data = data.DataGenerator.generate(p, n).assign(**{y_col: np.random.choice([0,1], size=n)})\n",
    "    \n",
    "    # pre-processing data\n",
    "    splits = RandomSplitter(valid_pct=.2)(all_train_data)\n",
    "\n",
    "    original_features = L([c for c in all_train_data.columns if c != 'id' and c != y_col])\n",
    "\n",
    "    to = TabularPandas(all_train_data, procs=[FillMissing, Normalize],\n",
    "                       cont_names=original_features,\n",
    "                       y_names=y_col,\n",
    "                       splits=splits)\n",
    "\n",
    "#     bs = 256\n",
    "    dls = to.dataloaders(bs=bs)\n",
    "    \n",
    "    # setting up the model\n",
    "    n_in = 2\n",
    "    n_flows = 3\n",
    "    n_z = 2\n",
    "    n_h = 200\n",
    "    p = .01\n",
    "\n",
    "    prior = distributions.MultivariateNormal(torch.zeros(n_z),\n",
    "                                             torch.eye(n_z)) # prior in latent space\n",
    "\n",
    "    encoder = flow.NNDiagGaussian(\n",
    "        mean_encoder_model=ae.get_encoder_model(n_in, n_h, p, n_z),\n",
    "        logvar_encoder_model=ae.get_encoder_model(n_in, n_h, p, n_z)\n",
    "    )\n",
    "\n",
    "    flows = [flow.Planar((n_z,)) for k in range(n_flows)]\n",
    "\n",
    "    decoder = flow.NNDiagGaussian(\n",
    "        ae.get_decoder_model(n_in, n_h, p, n_z),\n",
    "        ae.get_decoder_model(n_in, n_h, p, n_z),\n",
    "    )\n",
    "\n",
    "    model = flow.NormalizingFlow(prior, encoder, flows, decoder)\n",
    "    loss_func = flow.Flow_Loss()\n",
    "    \n",
    "    # training\n",
    "    learn = Learner(dls, model, loss_func=loss_func)\n",
    "    lrs = learn.lr_find()\n",
    "    learn.fit_one_cycle(epochs, lr_max=lrs.valley)\n",
    "    \n",
    "    # inspecting model generated data\n",
    "    (rec, ori, mu, logvar), _ = learn.get_preds(ds_idx=1)\n",
    "#     print(loss_func.loss(rec, ori, mu, logvar))\n",
    "    fig, report = utils.check_identifiability_of_generated_data(ori, rec, \n",
    "                                                  original_features)\n",
    "    \n",
    "    fig.show()\n",
    "    print(report)\n",
    "\n",
    "params = {\n",
    "    'p':pattern, \n",
    "    'n':n_data, \n",
    "    'epochs':n_epoch, \n",
    "    'n_flows':n_flows,\n",
    "    'bs': bs,\n",
    "}\n",
    "out = widgets.interactive_output(run_stuff, params)\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57357a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as distrib\n",
    "import torch.distributions.transforms as transforms\n",
    "\n",
    "\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
    "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec952f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'{z=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.as_tensor(z, dtype=torch.float)\n",
    "print(f'{z=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd036c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.zeros(2, dtype=torch.float)\n",
    "cov = torch.eye(2, dtype=torch.float)\n",
    "print(f'{mu=}\\n{cov=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ebc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial distribution\n",
    "q0 = distrib.MultivariateNormal(mu, \n",
    "                                covariance_matrix=cov)\n",
    "# Defining Affine Transformation\n",
    "# f1 = transforms.ExpTransform()\n",
    "f1 = transforms.PowerTransform(2)\n",
    "# Transforming\n",
    "q1 = distrib.TransformedDistribution(q0, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34349155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q0.log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c25156",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(q0(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1.log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71cc871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
